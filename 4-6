#4 Hebbian 
import numpy as np
import pandas as pd
W= np.array([1,-1,0,0.5]).transpose()
xi = [np.array([1,-2,1.5,0]).transpose(), np.array ([1, -0.5, -2, -1.5]).transpose(), np.array ([0, 1, -1, 1.5]).transpose() ]
c = 1
i = 0
print (W)
print(xi)
for i in range(len(xi)):
  net = sum(W.transpose() * xi[1])
  print("net: ",net)
  fnet = np.sign(net)
  print("fnet: ",fnet)
  dw = c * fnet * xi[1]
  print("dw: ",dw)
  W = W + dw
  print("W: ",W)

#5 Perceptron  

import numpy as np
import pandas as pd
W= np.array([1,-1,0,0.5]).transpose()
xi = [np.array([1,-2,1.5,0]).transpose(), np.array ([1, -0.5, -2, -1.5]).transpose(), np.array ([0, 1, -1, 1.5]).transpose() ]
c = 1
i = 0
d = np.array([-1, -1, 1])
print(d)
print(W)
print(xi)
for i in range(len(xi)):
  net = sum(W.transpose() * xi[i])
  print('aggregation output: ', round (net, 3))
  o = np.sign(net)
  print('o, round(o,3)')
  if o == d[i]:
    print('''since d = o, therefore, no need of updation of weights''')
  else:
    dw = c * (d[i] - o) * xi[i]
    W = W + dw
    print('weight vector for this iteration:', W)
  i += 1

#6 Delta 

#DELTA LEARNING RULE
import numpy as np
import pandas as pd
w = np.array([1, -1, 0, 0.5]).transpose()
xi = [np.array([1, -2, 0, -1]).transpose(),
np.array([0, 1.5, 0.5, -1]).transpose(),
np.array([-1, 1, 0.5, -1]).transpose()]
d = [- 1, 1, 1]
c = 0.1
error = 1
iteration = 0
i = 0
j = 0
print(w)
print(xi)
for i in range(len(xi)):
  net = sum(w.transpose() * xi[i])
  print("net: ", net)
  o = (2 / (1 + np.exp(-1 * net))) - 1
  o = 0.5 * (1 - o**2)
  error = d[i] - o
  print("error")
  Error = round(error, 1)
  dw = c * error * o * xi[i]
  w = w + dw
print("weight matrix: ", format(w))
